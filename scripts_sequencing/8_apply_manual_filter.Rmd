---
title: "Manual Filtering"
author: "M Fisher"
date: "4/27/2023"
output: html_document
---

# Description

Use this script to: 

(1) Get BLAST output for species flagged as 'non-native' during manual filtering, to check percent identity and e-values.

(2) Apply the manual filter

(3) Create a final data file with taxonomy / sequences for ASVs combined across runs, and all ASVs in each EGC sample

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(here)
library(ggplot2)
library(ggrepel)
library(cowplot)
library(janitor)
library(magrittr)

source(here('R','get_unique_taxa.R'))

# User inputs
dada2dir <- 'data/dada2'
blastdir <- 'data/blast'
indir   <- 'data/results'
run.nums <- c(2,3,4,5)
marker  <- 'BF3'
metadata_dir <- 'data/metadata'
blast_filename <- c('hash_key_clean_blast_2023-04-26.fasta')

```


# 1. Data

Read in the files with unique taxa across all runs (produced by script 7)
```{r}
# summary of taxonomy across all samples
unq.summary <- read_csv( here(indir,'allRuns_BF3_filtered_unique_taxa_summary.csv'))

# taxonomy per hash per crab
dat.out <- read_csv(here(blastdir,paste0('runs',first(run.nums),'-',last(run.nums),'_',marker,'_taxonomy_filtered.csv')))
```
read in the raw blasted taxonomy data 
```{r}
for(i in seq(1,length(run.nums))){
  r=run.nums[[i]]
  if(r==run.nums[1]){
    rawblastdat <- read_delim(here(blastdir, paste0("run",r,"_",blast_filename)), col_names=FALSE, col_types=rep("c",times=18)) %>% mutate(MiSeqRun=r)
  } else{
    rawblastdat %<>% bind_rows(read_delim(here(blastdir, paste0("run",r,"_",blast_filename)), col_names=FALSE, col_types=rep("c",times=18))
                            %>% mutate(MiSeqRun=r,X15=as.character(X15)))
  }
}
colnames(rawblastdat) <- c("qseqid", "sseqid", "sacc", "pident", "length",
                        "mismatch", "gapopen", "qcovus", "qstart", "qend", "sstart", "send", "evalue", "bitscore", "staxids", "qlen", "sscinames", "sseq","MiSeqRun")
```

read in the sequences associated with each hash
```{r}
for(i in seq(1,length(run.nums))){
  r=run.nums[[i]]
  if(r==run.nums[1]){
    hash_keys <- read_delim(here(dada2dir, paste0("run_",r),"hash_key.csv"), col_names=TRUE, col_types=rep("c",times=3)) %>% mutate(MiSeqRun=r)
  } else{
    hash_keys %<>% bind_rows(read_delim(here(dada2dir, paste0("run_",r),"hash_key.csv"), col_names=TRUE, col_types=rep("c",times=3))
                            %>% mutate(MiSeqRun=r))
  }
}
```


# 2. BLAST percent identities

while conducting manual filtering, it will be helpful to have percent identities associated with BLAST matches.

pull the percent identities for all taxa in the filtered file from (1), summarize across matches, and save.
```{r}
unq.pident <- unq.summary %>%
  filter(type=="Sample") %>%
  left_join(dat.out %>% dplyr::select(taxon,Hash) %>% distinct(), by="taxon") %>%
  left_join(rawblastdat,by=c("Hash"="qseqid")) %>%
  group_by(taxon,rank,phylum,class, family,genus, species,type,n_crab,miseqruns,sscinames) %>%
  summarise(min_pident=min(pident),max_pident=max(pident),mean_pident=mean(pident))
write_csv(unq.pident, here('data','results','allRuns_BF3_filtered_unique_taxa_summary_blastPIdent.csv'))
```


for previously undetected non-natives, it might be helpful to look at the raw blast data for all ASVs.
```{r eval=FALSE}

s <- "Neoporphyra haitensis"


asvdat <- dat.out %>% filter(taxon==s) %>% dplyr::select(Hash,MiSeqRun) %>% distinct()
tmp.blast.out <- asvdat %>% left_join(rawblastdat, by=c('Hash'='qseqid','MiSeqRun'))


write.csv(tmp.blast.out,file=here(paste0('tmpfile_',s,'.csv')))

```


# 3. Apply manual filter

Working from excel, I created the following file with manual filter information:
```{r}
manual.filter <- read_csv(here(indir,'allRuns_BF3_filtered_unique_taxa_summary_MANUALfilter.csv'))
```

delete the taxa marked for removal in the final list
```{r}
final.taxa <- manual.filter %>% filter(!is.na(taxon.final))
```


# 4. Final data

Create a final data file with sequences for ASVs combined across runs, and all ASVs in each EGC sample
```{r}
final.dat <- final.taxa %>%
  left_join(dat.out, by=c("taxon","rank")) %>%
  mutate(type=ifelse(type=="Samples","Sample",type)) %>% # fix inconsistent type if needed
  filter(type=="Sample") %>%
  dplyr::select(-filter) %>%
  mutate(species=ifelse(rank.final=="species" & is.na(species), taxon.final,species)) %>%  #Mya arenaria
  dplyr::select(sample,tech,site_month,taxon.final,rank.final,nReads,kingdom,phylum,class,order,family,genus,species,MiSeqRun,Hash) %>%
  left_join(hash_keys,by=c("Hash","MiSeqRun")) %>%
  distinct()

write_csv(final.dat, here(indir, 'allRuns_BF3_filtered_unique_taxa_manualFilter.csv'))
```

Next, remove the lower-level taxonomic information for IDs backed out to genus level or higher. 
```{r}
final.dat2 <- final.dat %>%
  mutate(species=ifelse(rank.final != "species" & !is.na(species),NA,species)) %>%
  mutate(genus=ifelse(!(rank.final %in% c("species","genus")) & !is.na(genus),NA,genus)) %>%
  mutate(family=ifelse(!(rank.final %in% c("species","genus","family")) & !is.na(family), NA, family)) %>%
  distinct()
```
```{r}
View(anti_join(final.dat2,final.dat))  # taxa that have been manually changed to higher taxonomic levels should all be reported here
View(anti_join(final.dat,final.dat2))  # taxa that have lower taxonomic info than rank level should all be reported here
```

Since some of the IDs were backed out to genus level or higher, based on manual checking of non-native status / percent identity in blast match, we have to again remove duplicated higher-level taxa from individual crab. So for example, if our manual change from an unclassified Ectocarpus species means that a crab has both an *Ectocarpus fasciculatus* and an *Ectocarpus* ID, we want to get rid of the *Ectocarpus* ID as a potentially non-unique taxa.
```{r}
final.dat.unq.nest <- final.dat2 %>%
  rename(rank=rank.final,taxon=taxon.final) %>%
  group_by(sample) %>%
  nest()

final.dat.unq.nest %<>% mutate(data.filter=purrr::map(data,get_unique_taxa))   ## improved function



final.dat.unq <-  final.dat.unq.nest %>% dplyr::select(-data) %>% unnest(c(sample,data.filter))
```

Let's check what was removed
```{r}
dat.check <- anti_join(rename(final.dat2, rank=rank.final,taxon=taxon.final), final.dat.unq) %>% distinct()

# View(filter(final.dat.unq,sample=="WACO21-340" & genus=="Hemigrapsus"))
```


```{r}
write_csv(final.dat.unq, here(indir, 'allRuns_BF3_filtered_FINAL_unique_taxa.csv'))
```


Create a final summary data file with taxonomy combined across runs / crabs. This will involve removing any lower-level taxa for ASVs that were manually adjusted to higher-level classifications (non-native taxa with lower percent identity scores; BOLD specimens that are unclassified species)
```{r}
final.dat.unq %>%
  group_by(taxon,rank,phylum,class,order,family,genus,species) %>%
  summarise(n_crab=length(unique(sample)),
            miseqruns=paste0(unique(MiSeqRun),collapse=","),
            site_months=paste0(unique(site_month),collapse=",")) %>%
  write_csv(here(indir, 'allRuns_BF3_filtered_FINAL_unique_taxa_summary.csv'))
```



# 6. ASVs

For the paper supplement, create a file with all unique ASVs that were matched to taxonomy in BLAST, and if/why they  were removed  from the final dataset.

First, read in the previous filtering information from script 6
```{r}
for(r in run.nums){
  if(r==first(run.nums)){
    track_filter_s6 <- read_csv(here(blastdir, paste0("run",r,"_",marker,"_taxonomy_track_filter.csv")))
  } else{
    track_filter_s6 %<>% bind_rows(
      read_csv(here(blastdir, paste0("run",r,"_",marker,"_taxonomy_track_filter.csv")))
    )
  }
}
```

Re-read in the final, manually filtered data set
```{r}
manual.filter <- read_csv(here(indir,'allRuns_BF3_filtered_unique_taxa_summary_MANUALfilter.csv'))

final.dat2 <- read_csv(here(indir, 'allRuns_BF3_filtered_FINAL_unique_taxa.csv'))
```

Mark ASVs removed manually
```{r}
track_filter <- track_filter_s6 %>%
  left_join(manual.filter %>%
              rename(manual_rm=filter),by=c("taxon","rank"))
```


Some manual filtering removed non-target taxa that weren't captured in script 6. For these, switch the `nonTarget_rm` column from `0` to `1` and delete the notes in the manual filter column. Then differentiate between taxa that were removed in the manual filter, and taxa that were edited (e.g., backed out to genus) during the manual filtering step. 
```{r}
track_filter %<>% mutate(nonTarget_rm=ifelse(nonTarget_rm==0 & manual_rm %in% c("too small","non-target"), 1, 0)) %>%
  mutate(manual_rm=ifelse(nonTarget_rm==1,0,
                          ifelse(is.na(manual_rm),0,manual_rm))) %>%
  mutate(manual_edit_notes=ifelse(!is.na(manual_rm) & !is.na(rank.final), manual_rm,0))

track_filter %<>% mutate(manual_rm=ifelse(manual_edit_notes!=0,0,manual_rm))
```


We did some additional filtering of ASVs to account for duplicates at higher taxonomic levels, after applying the manual filter above. Mark these as removed too.
```{r}
tmp_filter <- track_filter %>% filter(!is.na(taxon.final) & manual_rm==0 & manual_edit_notes==0) %>%
  filter(type %in% c("Sample","Samples"))

any(!(final.dat2$Hash %in% tmp_filter$Hash)) # if TRUE, use next code block
```
```{r}
tmp_filter <- tmp_filter %>% mutate(manual_rm=ifelse(Hash %in% final.dat2$Hash, "0", "not unique low-specificity ID"))

tmp_to_edit <- tmp_filter %>% filter(manual_rm != "0") 
# View(tmp_to_edit)

track_filter %<>% 
  anti_join(tmp_to_edit %>% dplyr::select(-manual_rm)) %>%
  bind_rows(tmp_to_edit)
# View(filter(track_filter, Hash %in% tmp_to_edit$Hash))
```

Do some re-arranging of columns for nicer output
```{r}
track_filter %<>%
  mutate(manual_filter_notes=ifelse(manual_rm != 0, manual_rm, 0)) %>%
  mutate(manual_rm=ifelse(manual_rm != 0, 1, 0)) %>%
  mutate(retained=ifelse(!is.na(taxon.final) & manual_rm==0,1,0)) %>%
  rename(in_control=control_rm, predator=predator_rm, nonTarget=nonTarget_rm,manual_filter=manual_rm) %>%
  pivot_longer(cols=c("human_contamination","in_control","predator","nonTarget","manual_filter","retained"), names_to="filter", values_to="tmpvals")

track_filter %<>% filter(tmpvals==1) %>% dplyr::select(-tmpvals)

track_filter %<>% mutate(manual_filter_notes=ifelse(manual_edit_notes!="0",manual_edit_notes,manual_filter_notes))
track_filter %<>% dplyr::select(-manual_edit_notes)
```


Attach the sequences to the unique identifiers 
```{r}
track_filter %<>%
  filter(type %in% c("Sample","Samples")) %>% dplyr::select(-type) %>%
  left_join(hash_keys, by=c("Hash","MiSeqRun"))

any(is.na(track_filter$Sequence))
all(track_filter$Hash %in% track_filter_s6$Hash)
```

Double check the ASVs marked 'retain' against our final data set.
```{r}
track_filter_retain <- filter(track_filter, filter=="retained")

# did we retain any hashes that aren't in the final data set? If TRUE, go to code block below
any(!(track_filter_retain$Hash %in% final.dat2$Hash))
# View(filter(track_filter_retain, !(Hash %in% final.dat2$Hash)))

# did we fail to retain hashes in the final data set?
any(!(final.dat2$Hash %in% track_filter_retain$Hash))
# check_hashes <- final.dat2$Hash[which(!(final.dat2$Hash %in% track_filter_retain$Hash))]
# View(filter(track_filter, Hash %in% check_hashes))
```
```{r}
tmp_filter <- track_filter_retain %>% filter(!(Hash %in% final.dat2$Hash)) %>%
  mutate(filter="manual_filter") %>%
  mutate(manual_filter_notes2="not unique low-specificity ID") %>%
  unite(col="manual_filter_notes", manual_filter_notes2,manual_filter_notes, sep=". AND ")

tmp_to_edit <- tmp_filter %>% filter(filter=="manual_filter") 
# View(tmp_to_edit)

track_filter %<>% 
  anti_join(tmp_to_edit %>% dplyr::select(-filter, -manual_filter_notes)) %>%
  bind_rows(tmp_to_edit)
# View(filter(track_filter, Hash %in% tmp_to_edit$Hash))


```
Double check the ASVs marked 'retain' against our final data set.
```{r}
track_filter_retain <- filter(track_filter, filter=="retained")

# did we retain any hashes that aren't in the final data set? 
all(track_filter_retain$Hash %in% final.dat2$Hash)

# did we fail to retain hashes in the final data set?
all(final.dat2$Hash %in% track_filter_retain$Hash)

# did we keep all the hashes in the original files?
all(track_filter$Hash %in% track_filter_s6$Hash)

```
Whew.

Save!
```{r}
track_filter %>%
  dplyr::select(Hash,taxon,rank,kingdom,phylum,class,order,family,genus,species,MiSeqRun,n.crab,reads.in.run,taxon.final,rank.final,filter,manual_filter_notes,Sequence) %>%
write_csv(here(indir,'S1_Table.csv'))
```






# 7. Compare to previous version?

```{r}
final.summary2 <- final.dat.unq %>%
  group_by(taxon,rank,phylum,class,order,family,genus,species) %>%
  summarise(n_crab=length(unique(sample)),
            miseqruns=paste0(unique(MiSeqRun),collapse=","),
            site_months=paste0(unique(site_month),collapse=","))

final.summary <-  read_csv(here(indir, 'allRuns_BF3_filtered_FINAL_unique_taxa_summary.csv'),
                           col_types='ccccccccicc')
```

```{r}
final.dat.unq0 <- read_csv(here(indir, 'allRuns_BF3_filtered_FINAL_unique_taxa.csv'))
```

```{r}
compare.version <- final.summary2 %>% mutate(version='mar') %>%
  left_join(final.summary %>% mutate(version='feb'))
```

```{r}
compare.version <- final.dat.unq %>% mutate(version='mar') %>%
  left_join(final.dat.unq0 %>% mutate(version='feb'))

dim(compare.version);dim(final.dat.unq0);dim(final.dat.unq)
```